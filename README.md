# full_attention
Full attention for neural networks
